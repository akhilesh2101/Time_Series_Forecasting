---
title: "FORECASTING US QUARTERLY HOUSING PRICES"
subtitle: "Final Project"

author: "Akhilesh Sureddi"
format: html
embed-resources: true
code-fold: true
editor: visual
knitr:
  opts_chunk:
    echo: TRUE
    warning: FALSE
    message: FALSE
---

```{r}
#| include: false
library(tidyverse)
library(rmarkdown)
library(gapminder)
library(janitor)
library(lubridate)
library(scales)
library(patchwork)
library(kableExtra)
library(data.table)
library(corrplot)
library(forecast)
library(zoo)
library(tseries) # For ADF/KPSS tests
library(tsibble)
library(fable)
library(feasts)
library(prophet)
```

In this Assignment, I will be trying to make a forecast model of the Quarterly US housing prices using the data picked up from <https://fred.stlouisfed.org/>Federal Reserve Economic Data . The data is published as a single line chart showing the trend of housing since 1963 and no prior data is included.

Data-set has only 2 columns, Date column along with the quarterly average US housing prices.

```{r}
data<-read_csv('MSPUS.csv')
colnames(data)<-c("date","value")
data <- 
  data %>% 
  mutate(date = yearquarter(as.yearqtr(date,format = "%Y-%m-%d")))%>% 
  filter(date>ymd("1980-01-01")) %>% 
  select(date,value) %>% 
  as_tsibble()
attach(data)
print(data)
```

Instead of looking at the entire data, I will be looking at data form 1980 to predict the last 10 years of housing prices. It'll be interesting to see if the recent trends would be captured using this.

```{r}
train = data %>%  # Train set
  filter(date<ymd("2012-01-01"))

test = data %>% # Test set
  filter(date>=ymd("2012-01-01"))
```

The time series we have is mean non-stationary and follows a general upward trend.

```{r}
 train %>% ggplot(aes(x=date,y=value))+
  geom_line()+xlab("Date")+ylab("")+
  ggtitle("US Quarterly Housing Prices")+
  scale_y_continuous(labels=scales::dollar_format())
```

```{r}

boxplot<-train %>% ggplot()+
  geom_boxplot(aes("", value))+xlab("")+ylab("")+
  ggtitle("Boxplot")+
    scale_y_continuous(labels=scales::dollar_format())+
  theme_bw()

density<-train %>% ggplot()+
  geom_density(aes(value))+xlab("")+ylab("")+
  ggtitle("Density plot of the data")+
    scale_x_continuous(labels=scales::dollar_format())+
  scale_y_continuous(labels=scales::dollar_format())+
  theme_bw()

hist<-train %>% ggplot()+
  geom_histogram(aes(value))+xlab("")+ylab("")+
  ggtitle("Histogram")+
  scale_x_continuous(labels=scales::dollar_format())+
  theme_bw()


violin<-train %>% ggplot()+
  geom_violin(aes("", value))+xlab("")+ylab("")+
  ggtitle("Violin Plot")+
    scale_y_continuous(labels=scales::dollar_format())+
  theme_bw()

hist + violin + density + boxplot
```

The housing prices seem to be concentrated more around the lower end of the data and is skewed to the right, as can be expected of any realistic pricing data.

Same can be inferred from box-plot and the density plot.

```{Summary Table}

| Statistic     | Value         |
|---------------|:-----         |
| Number of obv |     239       |
| Mean          |   146570.29   | 
| Median        |    126000     |               
| Std_dev       |   106773.79   |
| Min           |    17800      |
| Max           |    454900     |

```

Looking at all the plots and the data in general, since these are housing prices, there seem to be no Outliers in the data . Prices seem to follow a general upward trend, which can be expected of a developed country like the U.S because of increasing commodity prices in general too.

There seems to be a spike every decade or so, but the recent spike can be considered an outlier, if that is the case. In general the trend seems to be moving upward and non-stationary.

```{r}

housing_ma<-train %>% arrange(date) %>% 
  mutate(ma_13_center=rollapply(value,width=13,FUN=mean,align="center",fill=NA))

housing_ma %>% 
  ggplot()+
  geom_line(aes(date,value))+
  geom_line(aes(date,ma_13_center),color='red')+
  theme_bw()+xlab("Date")+ylab("")+
  ggtitle("Moving average")+
  scale_y_continuous(labels=scales::dollar_format())
```

I visualized the 13th order moving average here after looking at a few orders

Since we looked at the moving average, next step is to look what happens when the trend is removed from the data.

The remainder here seems like white noise with no apparent trend .

```{r}

housing_decomp <- train %>%
  mutate(
    ma_13_center = rollapply(
      value,
      13,
      FUN = mean,
      align = "center", fill = NA
    )
  ) %>%
  mutate(resid = value - ma_13_center) %>%
  select(date, value, ma_13_center, resid)

housing_decomp_plot <- housing_decomp %>%
  pivot_longer(
    value:resid,
    names_to = "decomposition",
    values_to = "value"
  ) %>%
  mutate(
    decomposition = case_when(
      decomposition == "value" ~ "value",
      decomposition == "ma_13_center" ~ "Trend",
      decomposition == "resid" ~ "Remainder"
    )
  ) %>%
  mutate(
    decomposition = factor(
      decomposition,
      labels = c(
        "value",
        "Trend",
        "Remainder"
      ),
      levels = c(
        "value",
        "Trend",
        "Remainder"
      )
    )
  ) %>%
  ggplot() +
  geom_line(aes(date, value), size = 1) +
  facet_wrap(
    ~decomposition,
    nrow = 3,
    scales = "free"
  ) +
  theme_bw() +
  ylab("") +
  xlab("Years") +
  ggtitle(
    "Quarterly Housing Price = Trend + Remainder"
  )+  scale_y_continuous(labels=scales::dollar_format())


housing_decomp_plot
```

To check if the remainder is actually white noise, I took a look at the lag plots for the data, moving average and the remainder to see if there was still a correlation between the lag for the remainder term.

```{r}
housing_decomp_lag <- housing_decomp %>%
  drop_na() %>%
  mutate(across(where(is.numeric), list(lag = lag))) %>%
  select(
    date, value, value_lag,
    ma_13_center, ma_13_center_lag, resid, resid_lag
  )
```

```{r}
housing_decomp_auto <- housing_decomp_lag %>%
  drop_na()

cor_val <- round(cor(housing_decomp_auto$value, housing_decomp_auto$value_lag), 2)
cor_ma <- round(cor(housing_decomp_auto$ma_13_center_lag, housing_decomp_auto$ma_13_center), 2)
cor_resid <- round(cor(housing_decomp_auto$resid_lag, housing_decomp_auto$resid), 2)

Quarterly_price_plot <- housing_decomp_lag %>%
  ggplot() +
  geom_point(aes(value_lag, value)) +
  geom_smooth(aes(value_lag, value), method = "lm", se = F) +
  labs(
    title = "Quarterly_price",
    subtitle = paste("Cor = ", cor_val)
  ) +
  theme_bw()+
  ylab('Quarterly_price')+
  xlab('Quarterly_price (Lag)')+
  scale_y_continuous(labels=scales::dollar_format())+
  scale_x_continuous(labels=scales::dollar_format())+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

ma_13_center_plot <- housing_decomp_lag %>%
  ggplot() +
  geom_point(aes(ma_13_center_lag, ma_13_center)) +
  geom_smooth(aes(ma_13_center_lag, ma_13_center), method = "lm", se = F) +
  labs(
    title = "Moving Average",
    subtitle = paste("Cor = ", cor_ma)
  ) +
  theme_bw()+
  ylab('Moving Average')+
  xlab('Moving Average (Lag)')+
  scale_x_continuous(labels=scales::dollar_format())+
  scale_y_continuous(labels=scales::dollar_format())+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))



resid_plot <- housing_decomp_lag %>%
  ggplot() +
  geom_point(aes(resid_lag, resid)) +
  geom_smooth(aes(resid_lag, resid), method = "lm", se = F) +
  labs(
    title = "Remainder",
    subtitle = paste("Cor = ", cor_resid)
  ) +
  theme_bw()+
  ylab('Remainder')+
  xlab('Remainder (Lag)')+
  scale_x_continuous(labels=scales::dollar_format())+
  scale_y_continuous(labels=scales::dollar_format())+
      theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

Quarterly_price_plot + ma_13_center_plot + resid_plot
```

As the correlation remains low in the white noise, and the lag plots show so significant jumps either upto 4 lags, we can say that we're moving in the right direction to say that there is no trend or seasonality we're missing .

```{r}
housing_decomp_resi <- 
  housing_decomp %>% 
  select(date, resid) %>% 
  as_tsibble()

housing_decomp_resi %>% 
  gg_lag(resid,geom = "point", lags = 1:4)+
  geom_smooth(aes(color=NULL),method='lm',color='red',se=F)
```

# ARIMA Modeling :

Before we start fitting Arima models to our data, let's check to see if our data is mean and variance stationary, for the data generating process to be captured properly.

```{r}
data_ts_roll <- train %>%
  mutate(
    mean = zoo::rollmean(
      value, 
      k = 13, 
      fill = NA),
    sd = zoo::rollapply(
      value, 
      FUN = sd, 
      width = 13, 
      fill = NA)
  )

data_rollmean <- data_ts_roll %>%
  ggplot() +
    geom_line(aes(date, value)) +
  geom_line(aes(date, mean),color='blue') +
  theme_bw() +
  ggtitle("Rolling Average")+
  scale_y_continuous(labels=scales::dollar_format())+
  ylab("Quarterly Price") +
  xlab("Date")
```

Our data generating process is clearly not mean or variance stationary. So let's fit a appropriate transformation to change that.

```{r}
data_rollsd <- data_ts_roll %>%
  ggplot() +
  geom_line(aes(date, sd)) +
  geom_smooth(aes(date,sd),method='lm',se=F)+
  theme_bw() +
  ggtitle("SD of data(rolling window)")+
  scale_y_continuous(labels=scales::dollar_format())+
  ylab("Quarterly Price") +
  xlab("Date")

data_rollmean+ data_rollsd
```
Log differenced data is the only possible iteration that passed the KPSS test for me, so we will be forecasting using log values for ARIMA models. 
```{r}
data_diff <- train %>%
  mutate(
    value_log = log1p(value),
    value_diff = value - lag(value),
    value_log_diff = value_log - lag(value_log))

log_diffed_data<-data_diff %>%
  ggplot() +
  geom_line(aes(date, value_log_diff)) +
  theme_bw() +
  ggtitle("Log; First Difference") +
  ylab("") +
  xlab("Date")+
theme_bw()

LogDiff = data_diff %>%
mutate(
    log_diff_sd = zoo::rollapply(
      value_log_diff, 
      FUN = sd, 
      width = 13, 
      fill = NA)) %>%
ggplot()+
geom_line(aes(date,log_diff_sd))+
geom_smooth(aes(date,log_diff_sd),method='lm',se=F)+
theme_bw() +
ggtitle("SD of Log Differenced data,") +
ylab("") +
xlab("Date")+
theme_bw()

log_diffed_data+LogDiff
```

```{r}
# First difference - **stationary**
diff_value_kpss = data_diff %>% 
features(value_diff, unitroot_kpss)
diff_value_kpss


# Differenced log close value - Stationary
log_diff_kpss = data_diff %>%
features(value_log_diff, unitroot_kpss)
log_diff_kpss

```

Since our data is a upward time series, the ACF plots can look like an AR process, with the gradual dampening but this is probably not the case with it.

```{r}
train %>%
  gg_tsdisplay(value,plot_type='partial', lag=8) +
  labs(title="Raw Data", y="")
```

The ACF/ PACF plots of the box cox differenced data is dropping hints of an MA(2) process and since the data is stationary after the first difference, the order of integratiuon would be atelast 1.

So my best guess right now is that this is a ARIMA(0,1,2) data generating process.

ACF plots also confirm no seasanality

```{r}
data_diff %>%
  gg_tsdisplay(value_log_diff,plot_type='partial', lag=8) +
  labs(title="Raw Data", y="")
```

Looking at a few manually fit Arima models, so far ARIMA(1,1,2) seems to be the best model with the lowest AIC and BIC

Note that since we produced differenced data, although model 5 is ARIMA(1,0,2) it is interpreted as ARIMA(1,1,2)

```{r}
logdiffdata <- data_diff %>% select(date,value_log_diff)
```

```{r}
 models_bic = logdiffdata %>%
  model(
    mod1 = ARIMA(value_log_diff~pdq(0,1,2)+PDQ(0,0,0)),
    mod2 = ARIMA(value_log_diff~pdq(0,1,3)+PDQ(0,0,0)),
    mod3 = ARIMA(value_log_diff~pdq(1,1,2)+PDQ(0,0,0)),
    mod4 = ARIMA(value_log_diff~pdq(1,0,1)+PDQ(0,0,0)),
    mod5 = ARIMA(value_log_diff~pdq(1,0,2)+PDQ(0,0,0)),
    mod6 = ARIMA(value_log_diff~pdq(1,0,0)+PDQ(0,0,0)),
    mod7 = ARIMA(value_log_diff~pdq(0,0,2)+PDQ(0,0,0)),
    mod8 = ARIMA(value_log_diff~pdq(0,0,1)+PDQ(0,0,0)),
    mod9 = ARIMA(value_log_diff~pdq(2,0,0)+PDQ(0,0,0)),
  )

ARIMA_Results <- models_bic %>%
  glance() %>%
  arrange(BIC)

ARIMA_Results
```

Now, let's try fitting Auto ARIMA to get a different estimate on our model.

Auto ARIMA also arrives at the same model as the manually fit best models.

```{r}
arima_best_mod <- data_diff %>%
  model(ARIMA(log(value),approximation=F,stepwise=F)) %>% report()
```

After the residual checks, it does look like the auto arima did a good job of fitting the data since the residuals appear to be white noise.

There seem to be no significant spikes in the acf plot and the residuals seem to follow a normal distribution with a mean of zero.

```{r}
arima_best_mod %>%
  gg_tsresiduals()
```

The Ljung-Box test is also passed looking at different lag values here. 
```{r}
lag2 <- arima_best_mod %>%
  augment() %>%
  features(.innov, ljung_box, lag = 2, dof = 1)

lag5 <- arima_best_mod %>%
  augment() %>%
  features(.innov, ljung_box, lag = 5, dof = 1)

lag10 <- arima_best_mod %>%
  augment() %>%
  features(.innov, ljung_box, lag = 10, dof = 1)


table_lb <- data.frame(lag = c(2, 5, 10),
                          lb_stat = c(lag2$lb_stat, lag5$lb_stat, lag10$lb_stat),
                          pvalue = c(lag2$lb_pvalue, lag5$lb_pvalue, lag10$lb_pvalue))

kable(table_lb, digits = 3, format = 'simple', caption = "Box-Ljung Tests")
```

# Prophet Modeling :

```{r}
prophet_data = train %>% 
    rename(ds = date, # Have to name our date variable "ds"
    y = value)  # Have to name our time series "y"

orig_model = prophet(prophet_data) # Train Model

orig_future = make_future_dataframe(orig_model,periods = 365*5) # Create future data frame for predictions

orig_forecast = predict(orig_model,orig_future) # Get forecast
```

```{r}
plot(orig_model,orig_forecast)+
ylab(" ")+xlab(" ")+theme_bw()+
  ggtitle(" Original prophet model forecast")+
  scale_y_continuous(labels=scales::dollar_format())
```

Looking at the componentsm, it seems like the model is picking up some yearly seasonality in the data generating process, which we're concluded is not present in previous assessments by looking at lag plots and ACF and PACF plots.

```{r}
prophet_plot_components(orig_model,orig_forecast)
```

Let's also look at the change points determined by the model . I see one or two changes not captured.

```{r}
plot(orig_model,orig_forecast)+add_changepoints_to_plot(orig_model)+ylab(" ")+xlab(" ")+
  ggtitle(" Showing default changepoints")+theme_bw()+
  scale_y_continuous(labels=scales::dollar_format())
```

There are a few things off with the initial forecast. We need to keep the seasonality off and change the parameters to better capture the expected trend since this is housing prices and we expect it to trend upward even with the recent dip.

Changing N-changepoints did not help, but since we see the trend to be better captured after changing both changepoint_range and changepoint_prior_scale

```{r}
# Number of Changepoints

best_prophet = prophet(prophet_data,changepoint.range = 0.7,changepoint.prior.scale=0.1, weekly.seasonality = FALSE, yearly.seasonality = FALSE,)

forecast = predict(best_prophet,orig_future)

plot(best_prophet,forecast)+add_changepoints_to_plot(best_prophet)+ylab(" ")+xlab(" ")+
  ggtitle(" Best prophet model")+theme_bw()+
  scale_y_continuous(labels=scales::dollar_format())
```

Since we have a increasing time series, after looking into logistic models, we decided not to move forward with them and stay with the linear model. We are also going to ignore saturation points and they did not help here.

Holidays don't apply to us either since our data is quarterly.

# Model Comparision and Validation

Cross-validation is implemented on the naive, best ARIMA, best Prophet models identified above. We start with training length of 20 Quarters (or 5 years) and rolling window of 4 Quarters is considered on the training dataset. Forecast is made on the next 4 Quarters for each of the cross-validation sets. Performance evaluation is done using RMSE obtained on each of the three models. Plot below shows the RMSE for the Naive, best ARIMA and best Prophet models across the horizon.

```{r}
train_cv <- train |>
  stretch_tsibble(.init = 12*10, .step = 24)

naive_model <- train_cv %>%
  model(Naive = NAIVE(value)) %>%
  forecast(h = 36) %>%
  group_by(.id) %>%
  mutate(h = row_number()) %>%
  ungroup() %>%
  as_fable(response = "value", distribution = value)

accuracy_naive <- naive_model %>%
  accuracy(train, by = c("h", ".model"))

naive_drift_model <- train_cv %>%
  model(naive_w_drift = NAIVE(value ~ drift())) %>%
  forecast(h = 36) %>%
  group_by(.id) %>%
  mutate(h = row_number()) %>%
  ungroup() %>%
  as_fable(response = "value", distribution = value)

accuracy_naive_drift <- naive_drift_model %>%
  accuracy(train, by = c("h", ".model"))

best_arima <- train_cv %>%
  model(
    Arima = ARIMA(log(value),approximation=F)
  ) %>%
  forecast(h = 36) %>%
  group_by(.id) %>%
  mutate(h = row_number()) %>%
  ungroup() %>%
  as_fable(response = "value", distribution = value)

accuracy_arima <- best_arima %>%
  accuracy(train, by = c("h", ".model"))

accuracy_comparison <- accuracy_naive %>% 
  bind_rows(accuracy_arima) %>% 
  bind_rows(accuracy_naive_drift)

accuracy_comparison <- accuracy_comparison %>%
  rename(Horizon = h, Model = .model)

accuracy_comparison %>%
  ggplot()+
  geom_line(aes(Horizon,RMSE, color = Model)) +
  theme_bw() +
  xlab("Horizon (in Months)") +
  ylab("RMSE") +
  ggtitle("Model Performance Comparison Across Horizon"
    ,subtitle = "Comparing Naive, Best Arima,"
  ) +
  xlim(0, 13)
```


```{r}
cv <- cross_validation(best_prophet, initial = 10*365, period = 365, horizon = 365, units = 'days')
metrics1 = performance_metrics(cv, rolling_window = 0.3) %>% 
  mutate(model = 'Original')


g1=metrics1 %>% 
ggplot()+
geom_line(aes(horizon,rmse,color=model))+
  theme_bw()+
  xlab("Horizon (Days)")+
  ylab("RMSE")


g1 + 
  theme(legend.position = "bottom")
```

It can be inferred from the plot above that Naive model performs best across most of the horizon expect for when horizon is less than 2 months where ARIMA model works well. But the difference in RMSE seems not very significant between the two models. Also, it can be seen that RMSE increases as the forecast horizon increases, as we would expect.

Here I looked at the RMSE graphs for models and decided to move forward witht he Naive forecast as it seems to have the lowest RMSE values compared to all the rest of the models. 


```{r}
best_model = train %>%
  model(Naive = NAIVE(value))

best_model %>%
  forecast(h=48) %>%
  autoplot(
    train %>%
      select(date,value) %>%
      bind_rows(
        test %>%
        as_tsibble()
      )
  ) +
  geom_vline(aes(xintercept = ymd("2012-01-01")), color = "red", linetype = "dashed") +
  ggtitle("10-year Forecast vs Actual of Quarterly Housing Prices", subtitle = 'Naive Forecast')+
  scale_y_continuous(labels=scales::dollar_format())
```


The forecast as expected is off by a very large area. I expected the Prophet model to do better but the RMSE values suggested otherwise. 